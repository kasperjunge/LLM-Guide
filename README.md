# LLM-Guide ğŸš€

Welcome to LLM-Guide, a resource for training, hosting and using large language models (LLMs). This repository is designed to provide a central hub for researchers, developers, and enthusiasts who are interested in the latest developments in everything LLMs.

## Open Sources Projects ğŸ‘©â€ğŸ’»
  - [LangChain: âš¡ Building applications with LLMs through composability âš¡ï¸](https://github.com/hwchase17/langchain)
  - [Alpa: Training and serving large-scale neural networks](https://github.com/alpa-projects/alpa)
  - [Petals: ğŸŒ¸ Run 100B+ language models at home, BitTorrent-style.](https://github.com/bigscience-workshop/petals)
  - [Open Assistant: Open source ChatGPT-like model](https://open-assistant.io)
  - [Together: A decentralized cloud for artificial intelligence.](https://www.together.xyz/)
  - [Chroma: the open source embedding database](https://github.com/chroma-core/chroma)

## Models á¨
- [Bloom ğŸŒ¸: BigScience Large Open-science Open-access Multilingual Language Model](https://huggingface.co/bigscience/bloom)
- [OPT-175B: Democratizing access to large-scale language](https://forms.gle/BDB2i44QwCr2mCJN6)
- [GALACTICA 120B: trained on a large-scale scientific corpus](https://huggingface.co/facebook/galactica-120b)

## Providers ğŸ’»
- [OpenAI](https://openai.com/)
- [Cohere](https://cohere.ai/)
- [AI21labs](https://www.ai21.com/)
- [GooseAI](https://goose.ai/)
- [DeepInfra](https://deepinfra.com/)

## Tutorials ğŸ“
- [LangChain Tutorial (Video)](https://youtube.com/playlist?list=PLqZXAkvF1bPNQER9mLmDbntNfSpzdDIU5)
- [LangChain for Gen AI and LLMs (Video)](https://youtube.com/playlist?list=PLIUOU7oqGTLieV9uTIFMm6_4PXg-hlN6F)
- [langchain-tutorials (Notebook)](https://github.com/gkamradt/langchain-tutorials)

## People to Follow ğŸ’
- James Briggs: [Youtube](https://www.youtube.com/@jamesbriggs), [Twitter](https://twitter.com/jamescalam), [LinkedIn](https://www.linkedin.com/in/jamescalam/), [GitHub](https://github.com/jamescalam)
- Elvis Saravia: [Youtube](https://www.youtube.com/@elvissaravia), [Twitter](https://twitter.com/omarsar0), [LinkedIn](https://www.linkedin.com/in/omarsar/), [GitHub](https://github.com/dair-ai)
- [Data Independent](https://www.youtube.com/@DataIndependent)

## Papers ğŸ“œ
- [Language Models are Few-Shot Learners (GPT-3)](https://arxiv.org/abs/2005.14165)
- [Training language models to follow instructions with human feedback (InstructGPT)](https://arxiv.org/abs/2203.02155)
- [Scaling Language Models: Methods, Analysis & Insights from Training Gopher](https://arxiv.org/abs/2112.11446)

## Datasets ğŸ’¾
- [Anthropic: HH-RLHF](https://huggingface.co/datasets/Anthropic/hh-rlhf)
- [OpenAI: summarize_from_feedback](https://huggingface.co/datasets/openai/summarize_from_feedback)
